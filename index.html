<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">

    <title>Reinhard M. Grassmann</title>

    <meta content="Reinhard M. Grassmann" name="author">
    <meta content="width=device-width, initial-scale=1" name="viewport">

    <link href="stylesheet.css" rel="stylesheet" type="text/css">
    <link href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>&#10025;</text></svg>"
          rel="icon">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Reinhard M. Grassmann</name>
                        </p>
                        <p>
                            I am a Ph.D. Candidate with the Department of Computer Science and a research assistant with
                            the <a href="https://crl.utm.utoronto.ca/">Continuum Robotics Laboratory</a> at the
                            University of Toronto, Canada.
                            I work on continuum robotics and machine learning.
                            Before all that, I completed a B.Sc. and a M.Sc. Degree in Mechatronics at the <a
                                href="https://www.uni-hannover.de/en/">Leibniz University Hannover</a>, Germany in 2016
                            and 2018, respectively.
                            From 2018 to 2019 I worked as a research assistant at the Lehrstuhl fuer Kontinuumsrobotik
                            at the Leibniz University Hannover.
                        </p>
                        <p style="text-align:center">
                            <a href="mailto:reinhard.grassmann@utoronto.ca">Email</a> &nbsp/&nbsp
                            <a href="data/bio.txt">Bio</a> &nbsp/&nbsp
                            <a href="https://scholar.google.com/citations?hl=en&user=6nbw0sgAAAAJ">Google Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://github.com/reinhardgrassmann/">GitHub</a> &nbsp/&nbsp
                            <a href="https://www.semanticscholar.org/author/R.-Grassmann/65752777">Semantic Scholar</a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/ReinhardGrassmann_bw_circle.png"><img alt="profile photo"
                                                                              class="hoverZoomLink"
                                                                              src="images/ReinhardGrassmann_bw_circle.png"
                                                                              style="width:100%;max-width:100%"></a>
                    </td>
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <!-- RESEACH -->
                <tbody>

                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Research</heading>
                        <p>
                            I'm interested in continuum robotics, machine learning, and dual quaternions.
                            Aside from that, creativity, innovation, and philosophy of science are also part of my field of interest to some extent.
                        </p>
                        <p>
                            During my research adventures, I have gratefully collaborated or am still collaborating with
                            (in alphabetical order)
                            <a href="https://crl.utm.utoronto.ca/jbk.html">J. Burgner-Kahrs</a>,
                            <a href="https://ryan-zeyuan-chen.github.io/">R. Z. Chen</a>,
                            P. T. Dewi,
                            <a href="https://www.mirmi.tum.de/en/rsi/team/haddadin-sami/">S. Haddadin</a>,
                            <a href="https://taqihamoda.github.io/">T. Hamoda</a>,
                            L. Johannsmeier,
                            V. Modes,
                            P. Le,
                            N. Liang,
                            <a href="https://www.cs.toronto.edu/~slilge/">S. Lilge</a>,
                            <a href="https://team.inria.fr/defrost/team-members/quentin-peyron/">Q. Peyron</a>,
                            <a href="https://priyankarao257.github.io/">P. Rao</a>,
                            A. Senyk,
                            and,
                            <a href="https://www.cs.toronto.edu/~cshentu/">C. Shentu</a>.
                        </p>
                    </td>
                </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <!-- PAPER -->
                <tbody>

                <!--GrassmannBurgner-Kahrs_arXiv_2024b-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <img alt="clean-usnob" height="82" src="images/2024_arXiv_framework_tinywow.png" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle" valign="middle" width="100%">
                        <a href="https://doi.org/10.48550/arXiv.2412.16422">
                            <papertitle>Using Clarke Transform to Create a Framework on the Manifold: From Sampling via Trajectory Generation to Control
                            </papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>arXiv</em>, 2024
                        <br>
                        <a href="paper/GrassmannBurgner-Kahrs_arXiv_2024b.pdf">paper</a>
                        /
                        <a href="https://doi.org/10.48550/arXiv.2412.16422">arXiv</a>
                        /
                        <a href="data/GrassmannBurgner-Kahrs_arXiv_2024b.bib">BibTex</a>
                        <p>We propose to develop frameworks using Clarke coordinates that lead to canonical forms of the components of the frameworks.</p>
                        &#35;Manifold &#35;Representation &#35;ContinuumRobot
                    </td>
                </tr>

                <!--GrassmannBurgner-Kahrs_arXiv_2024a-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;background-color:#f4f5f4">
                        <img alt="clean-usnob" height="82" src="images/2024_arXiv_jointLocation_tinywow.png" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle;background-color:#f4f5f4" valign="middle" width="100%">
                        <a href="Xplore">
                            <papertitle>Clarke Transform and Encoder-Decoder Architecture for Arbitrary Joints Locations in Displacement-Actuated Continuum Robots
                            </papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>IEEE RoboSoft</em>, 2025
                        <br>
                        <a href="paper/GrassmannBurgner-Kahrs_arXiv_2024a.pdf">paper</a>
                        /
                        <a href="Xplore">IEEE Xplore</a>
                        /
                        <a href="https://doi.org/10.48550/arXiv.2412.16401">arXiv</a>
                        /
                        <a href="data/GrassmannBurgner-Kahrs_arXiv_2024a.bib">BibTex</a>
                        <p>The proposed encoder-decoder architecture allows us to consider novel mechanical design while reusing existing approaches.</p>
                        &#35;Manifold &#35;EncoderDecoder &#35;ContinuumRobot
                    </td>
                </tr>

                <!--GrassmannSenykBurgner-Kahrs_arXiv_2024-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <img alt="clean-usnob" height="82" src="images/2024_ClarkeTransform_tinywow.png" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle" valign="middle" width="100%">
                        <a href="https://doi.org/10.48550/arXiv.2409.16501">
                            <papertitle>Clarke Transform â€” A Fundamental Tool for Continuum Robotics
                            </papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="AnastasiiaSenyk">Anastasiia Senyk</a>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>arXiv</em>, 2024
                        <br>
                        <a href="paper/GrassmannSenykBurgner-Kahrs_arXiv_2024.pdf">paper</a>
                        /
                        <a href="https://arxiv.org/abs/2409.16501">arXiv</a>
                        /
                        <a href="data/GrassmannSenykBurgner-Kahrs_arXiv_2024.bib">BibTex</a>
                        /
                        <a href="paper/Clarke_Transform_Cheat_Sheet.pdf">Cheat Sheet</a>
                        /
                        <a href="https://doi.org/10.48550/arXiv.2409.13826">extended abstract (arXiv)</a>
                        <p>We propose the Clarke transform and Clarke coordinates enabling the development of methods on the two-dimensional manifold embedded in the n-dimensional joint space.</p>
                        &#35;Manifold &#35;Representation &#35;ContinuumRobot
                    </td>
                </tr>

                <!--GrassmannSenykBurgner-Kahrs_ICRA_2024-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;background-color:#f4f5f4">
                        <img alt="clean-usnob" height="82" src="images/2024_CTCR_Space_tinywow.png" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle;background-color:#f4f5f4" valign="middle" width="100%">
                        <a href="https://doi.org/10.1109/ICRA57147.2024.10610322">
                            <papertitle>On the Disentanglement of Tube Inequalities in Concentric Tube Continuum Robots
                            </papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="AnastasiiaSenyk">Anastasiia Senyk</a>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>IEEE ICRA</em>, 2024
                        <br>
                        <a href="paper/GrassmannSenykBurgner-Kahrs_ICRA_2024.pdf">paper</a>
                        /
                        <a href="https://doi.org/10.1109/ICRA57147.2024.10610322">IEEE Xplore</a>
                        /
                        <a href="https://arxiv.org/abs/2402.12587">arXiv</a>
                        /
                        <a href="data/GrassmannSenykBurgner-Kahrs_ICRA_2024.bib">BibTex</a>
                        <p>We derive and investigate the lower triangular transformation matrix to disentangle the tube inequalities.</p>
                        &#35;Disentanglement &#35;Representation &#35;ContinuumRobot
                    </td>
                </tr>

                <!--GrassmannBurgner-Kahrs_et_al_arXiv_2024-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <img alt="clean-usnob" height="90" src="images/2023_ActuationUnit_tinywow.jpg" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle" valign="middle" width="100%">
                        <a href="http://www.opencontinuumrobotics.com">
                            <papertitle>Open Continuum Robotics â€“ One Actuation Module to Create them All
                            </papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="https://scholar.google.com/citations?user=eLZ4kpAAAAAJ">Chengnan Shentu</a>,
                        <a href="TaqiHamoda">Taqi Hamoda</a>,
                        <a href="PuspitaTrianaDewi">Puspita Triana Dewi</a>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>Frontiers in Robotics and AI</em>, 2024
                        <br>
                        <a href="paper/GrassmannBurgner-Kahrs_et_al_arXiv_2024.pdf">paper</a>
                        /
                        <a href="https://arxiv.org/abs/2304.11850">arXiv</a>
                        /
                        <a href="https://doi.org/10.3389/frobt.2024.1272403">Front. Robot. AI</a>
                        /
                        <a href="data/GrassmannBurgner-Kahrs_et_al_Frontiers_2024.bib">BibTex</a>
                        /
                        <a href="http://www.opencontinuumrobotics.com">OpenCR Project</a>
                        <p>To democratize continuum robots research, we propose an actuation module to build torque-controlled continuum robots and provide open-source software and hardware with
our initiative called the Open Continuum Robotics Project.</p>
                        &#35;Design &#35;TorqueControl &#35;ContinuumRobot
                    </td>
                </tr>

                <!--GrassmannBurgner-Kahrs_et_al_IROS_2022-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;background-color:#f4f5f4">
                        <img alt="clean-usnob" height="109" src="images/2022_IROS_setup_tinywow.png" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle;background-color:#f4f5f4" valign="middle" width="100%">
                        <a href="https://doi.org/10.1109/IROS47612.2022.9981719">
                            <papertitle>A Dataset and Benchmark for Learning the Kinematics of Concentric Tube Continuum
                                Robots
                            </papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="https://scholar.google.com/citations?user=AUVj0LYAAAAJ">Ryan Zeyuan Chen</a>,
                        <a href="https://scholar.google.ca/citations?user=0h1At3cAAAAJ">Nan Liang</a>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>IEEE/RAS IROS</em>, 2022
                        <br>
                        <a href="paper/GrassmannBurgner-Kahrs_et_al_IROS_2022.pdf">paper</a>
                        /
                        <a href="https://doi.org/10.1109/IROS47612.2022.9981719">IEEE Xplore</a>
                        /
                        <a href="data/GrassmannBurgner-Kahrs_et_al_IROS_2022.bib">BibTex</a>
                        /
                        <a href="https://github.com/ContinuumRoboticsLab/CRL-Dataset-CTCR-Pose">GitHub</a>
                        <p>We provide the first public dataset for a three-tube CTCR to democratize research on
                            learning-based and physics-based modelling of the kinematics.</p>
                        &#35;Dataset &#35;MachineLearning &#35;ContinuumRobot
                    </td>
                </tr>

                <!--GrassmannBurgner-Kahrs_et_al_Frontiers_2022-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <img alt="clean-usnob" height="156" src="images/2022_dof_tinywow.jpg" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle" valign="middle" width="100%">
                        <a href="https://doi.org/10.3389/frobt.2022.873446">
                            <papertitle>FAS -- A Fully Actuated Segment for Tendon-Driven Continuum Robots</papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="https://scholar.google.com/citations?user=0rQBVRQAAAAJ">Priyanka Rao</a>,
                        <a href="https://scholar.google.com/citations?user=IvJpoQcAAAAJ">Quentin Peyron</a>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>Frontiers in Robotics and AI</em>, 2022
                        <br>
                        <a href="https://www.frontiersin.org/articles/10.3389/frobt.2022.873446/pdf">paper</a>
                        /
                        <a href="https://doi.org/10.3389/frobt.2022.873446">Front. Robot. AI</a>
                        /
                        <a href="data/GrassmannBurgner-Kahrs_et_al_Frontiers_2022.bib">BibTex</a>
                        <p>To achieve variable tendon routing, we propose a segment design that combines two distinct characteristics of tendon-driven
                            continuum robots, i.e. variable length and non-straight tendon routing, into a single
                            segment by enabling rotation of its backbone.</p>
                        &#35;Design &#35;VariableTendonRouting &#35;ContinuumRobot
                    </td>
                </tr>

                <!--LianBurgner-Kahrs_et_al_ICRA_2021-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;background-color:#f4f5f4">
                        <img alt="clean-usnob" height="92" src="images/2020_Image2joint_tinywow.png" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle;background-color:#f4f5f4" valign="middle" width="100%">
                        <a href="https://doi.org/10.1109/ICRA48506.2021.9562085">
                            <papertitle>Learning-based Inverse Kinematics from Shape as Input for Concentric Tube
                                Continuum Robots
                            </papertitle>
                        </a>
                        <br>
                        <a href="https://scholar.google.ca/citations?user=0h1At3cAAAAJ">Nan Liang</a>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="https://www.cs.toronto.edu/~slilge/">Sven Lilge</a>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>IEEE ICRA</em>, 2021
                        <br>
                        <a href="paper/LiangBurgner-Kahrs_et_al_ICRA_2021.pdf">paper</a>
                        /
                        <a href="https://doi.org/10.1109/ICRA48506.2021.9562085">IEEE Xplore</a>
                        /
                        <a href="data/LiangBurgner-Kahrs_et_al_ICRA_2021.bib">BibTex</a>
                        <p>We introduce methodologies to compute the inverse kinematics for concentric tube continuum
                            robots from a desired shape as input.</p>
                        &#35;MachineLearning &#35;ShapeRepresentation &#35;ContinuumRobot
                    </td>
                </tr>

                <!--GrassmannBurgner-Kahrs_et_al_RSS_WS_2020-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <img alt="clean-usnob" height="62"
                             src="images/2020_PrototypeDevelopmentSystemThinking_tinywow.png" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle" valign="middle" width="100%">
                        <a href="https://openreview.net/forum?id=bYLFxFQPFtX">
                            <papertitle>CTCR Prototype Development: An Obstacle in the Research Community?</papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="https://www.cs.toronto.edu/~slilge/">Sven Lilge</a>,
                        <a href="PhuongLe">Phuong Le</a>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>IFRR RSS Workshop on Retrospectives in Robotics</em>, 2020
                        <br>
                        <a href="paper/GrassmannBurgner-Kahrs_et_al_RSS_WS_2020.pdf">paper</a>
                        /
                        <a href="https://openreview.net/forum?id=bYLFxFQPFtX">OpenReview</a>
                        /
                        <a href="https://sites.google.com/stanford.edu/roboticsretrospectives/home">RSS Workshop:
                            Robotics Retrospectives</a>
                        /
                        <a href="https://www.youtube.com/watch?v=H3UjwT7rNns">YouTube</a>
                        /
                        <a href="data/GrassmannBurgner-Kahrs_et_al_RSS_WS_2020.bib">BibTex</a>
                        <p>We discuss the impact of the current habit of developing a variety of different prototypes on
                            the emergence of a ubiquitous robotic platform.</p>
                        &#35;SystemThinking &#35;ContinuumRobot
                    </td>
                </tr>

                <!--GrassmannBurgner-Kahrs_RA-L_2019-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;background-color:#f4f5f4">
                        <img alt="clean-usnob" height="180" src="images/2019_TrajectoryGeneration_tinywow.png"
                             width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle;background-color:#f4f5f4" valign="middle" width="100%">
                        <a href="https://doi.org/10.1109/LRA.2019.2931133">
                            <papertitle>Quaternion-Based Smooth Trajectory Generator for Via Poses in SE(3) Considering
                                Kinematic Limits in Cartesian Space
                            </papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>IEEE RA-L</em>, 2019
                        <br>
                        <a href="paper/GrassmannBurgner-Kahrs_RA-L_2019.pdf">paper</a>
                        /
                        <a href="https://doi.org/10.1109/LRA.2019.2931133">IEEE Xplore</a>
                        /
                        <a href="data/GrassmannBurgner-Kahrs_RA-L_2019.bib">BibTex</a>
                        <p>We address the problem of generating a singularity-free trajectory for multiple via poses in
                            SE(3), while complying with the requirement of C4 continuity.</p>
                        &#35;TrajectoryGeneration &#35;Quaternion &#35;LightWeightRobot
                    </td>
                </tr>

                <!--GrassmannBurgner-Kahrs_RSS_2019-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <img alt="clean-usnob" height="137" src="images/2019_RotationErrorComparision_tinywow.png"
                             width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle" valign="middle" width="100%">
                        <a href="https://doi.org/10.15607/RSS.2019.XV.017">
                            <papertitle>On the Merits of Joint Space and Orientation Representations in Learning the
                                Forward Kinematics in SE(3)
                            </papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>IFRR RSS</em>, 2019
                        <br>
                        <a href="http://roboticsproceedings.org/rss15/p17.pdf">paper</a>
                        /
                        <a href="http://roboticsproceedings.org/rss15/p17.html">RSS XV</a>
                        /
                        <a href="data/GrassmannBurgner-Kahrs_RSS_2019.bib">BibTex</a>
                        /
                        <a href="paper/GrassmannBurgner-Kahrs_RSS_2019_Poster.pdf">Poster</a>
                        <p>We investigate the influence of different joint space and orientation representations on the
                            approximation of the forward kinematics.</p>
                        &#35;MachineLearning &#35;Quaternion &#35;ContinuumRobot
                    </td>
                </tr>

                <!--GrassmannJohannsmeierHaddadin_IROS_2018-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;background-color:#f4f5f4">
                        <img alt="clean-usnob" height="104" src="images/2018_PathScheduling_tinywow.png" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle;background-color:#f4f5f4" valign="middle" width="100%">
                        <a href="https://doi.org/10.1109/IROS.2018.8594339">
                            <papertitle>Smooth Point-to-Point Trajectory Planning in SE(3) with Self-Collision and Joint
                                Constraints Avoidance
                            </papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="https://scholar.google.ca/citations?user=cLa2JooAAAAJ">Lars Johannsmeier</a>,
                        <a href="https://scholar.google.ca/citations?user=H1v0ztEAAAAJ">Sami Haddadin</a>
                        <br>
                        <em>IEEE/RSJ IROS</em>, 2018
                        <br>
                        <br><a href="paper/GrassmannJohannsmeierHaddadin_IROS_2018.pdf">paper</a>
                        /
                        <a href="https://doi.org/10.1109/IROS.2018.8594339">IEEE Xplore</a>
                        /
                        <a href="data/GrassmannJohannsmeierHaddadin_IROS_2018.bib">BibTex</a>
                        <p>We introduce a point-to-point trajectory planner for serial robotic structures that combines
                            the ability to avoid self-collisions and to respect motion constraints, while complying with
                            the requirement of being C4 continuous.</p>
                        &#35;TrajectoryGeneration &#35;Quaternion &#35;LightWeightRobot
                    </td>
                </tr>

                <!--GrassmannModesBurgner-Kahrs_et_al_IROS_2018-->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <img alt="clean-usnob" height="119" src="images/2018_IROS_PosError_tinywow.png" width="160">
                    </td>
                    <td style="padding:10px;vertical-align:middle" valign="middle" width="100%">
                        <a href="https://doi.org/10.1109/IROS.2018.8594451">
                            <papertitle>Learning the Forward and Inverse Kinematics of a 6-DOF Concentric Tube Continuum
                                Robot in SE(3)
                            </papertitle>
                        </a>
                        <br>
                        <strong>Reinhard M. Grassmann</strong>,
                        <a href="VincentModes">Vincent Modes</a>,
                        <a href="https://scholar.google.com/citations?user=JtHZL24AAAAJ">Jessica Burgner-Kahrs</a>
                        <br>
                        <em>IEEE/RSJ IROS</em>, 2018
                        <br><a href="paper/GrassmannModesBurgner-Kahrs_IROS_2018.pdf">paper</a>
                        /
                        <a href="https://doi.org/10.1109/IROS.2018.8594451">IEEE Xplore</a>
                        /
                        <a href="data/GrassmannModesBurgner-Kahrs_IROS_2018.bib">BibTex</a>
                        <p>We introduce a joint description to learn the forward and inverse kinematics for concentric
                            tube continuum robots from real robot measurements.</p>
                        &#35;MachineLearning &#35;Quaternion &#35;ContinuumRobot
                    </td>
                </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <!-- THESES -->
                <tbody>

                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Theses</heading>
                        <p>
                            Theses that I wrote during my mechatronics studies at <a
                                href="https://www.uni-hannover.de/en/">Leibniz University Hannover</a>.
                        </p>
                    </td>
                </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <!-- THESES -->
                <tbody>

                <!-- Masterarbeit -->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <img alt="clean-usnob" height="114" src="images/Thesis_MA_tinywow.png" width="160">
                    </td>
                    <td valign="middle" width="100%">
                        <p><i>"Artificial Neural Networks for Learning Forward and Inverse Kinematics of Tubular
                            Continuum Robots"</i></p>
                        <p><strong>Masterâ€™s thesis</strong> supervised by <a href="https://de.wikipedia.org/wiki/Jessica_Burgner-Kahrs">Prof.
                            Dr.-Ing. Jessica Burgner-Kahrs</a></p>
                        <p>Thesis was awarded the <a href="https://www.uni-hannover.de/fileadmin/luh/content/pressestelle/uniintern/2018/uniintern_18_11.pdf">Honoree of the NiedersachsenMetall Foundation</a> for outstanding achievements at the Faculty of Mechanical Engineering, LUH, Germany.</p>
                        <p>Some of the results have been published in <a href="https://doi.org/10.1109/IROS.2018.8594451">IROS 2018</a>.</p>
                    </td>
                </tr>

                <!-- Bachelorarbeit -->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;background-color:#f4f5f4">
                        <img alt="clean-usnob" height="160" src="images/Thesis_BA_tinywow.png" width="160">
                    </td>
                    <td style="background-color:#f4f5f4" valign="middle" width="100%">
                        <p><i>"Generating Smooth Trajectories for Obstacle Avoidance via Quaternions in Cartesian
                            Space"</i></p>
                        <p><strong>Bachelorâ€™s thesis</strong> supervised by <a href="https://en.wikipedia.org/wiki/Sami_Haddadin">Prof. Dr.-Ing. Sami
                            Haddadin</a></p>
                        <p>Some of the results have been published in <a href="https://doi.org/10.1109/IROS.2018.8594339">IROS 2018</a>.</p>
                    </td>
                </tr>

                <!-- Studienarbeit -->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <img alt="clean-usnob" height="160" src="images/Thesis_SA_tinywow.png" width="160">
                    </td>
                    <td valign="middle" width="100%">
                        <p><i>"Data Fusion Using an Extended Kalman Filter for an Optically Navigated Light Weight
                            Robot"</i></p>
                        <p><strong>Project thesis</strong> supervised by Prof. Dr.-Ing. Tobias Ortmaier</p>
                    </td>
                </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <!-- PROJECTS -->
                <tbody>

                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Research Projects</heading>
                        <p>
                            Research projects with my involvement.
                        </p>
                    </td>
                </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <!-- PROJECTS -->
                <tbody>

                <!-- Open Continuum Robotics Project -->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;background-color:#f4f5f4">
                        <img alt="clean-usnob" height="95" src="images/Project_OpenCR_tinywow.png" width="160">
                    </td>
                    <td style="background-color:#f4f5f4" valign="middle" width="100%">
                        <p><i>"Open Continuum Robotics Project"</i> (<a href="https://www.opencontinuumrobotics.com/">link to OpenCR Project</a>, <a href="https://crl.utm.utoronto.ca/_pages/opencr.html">link to project description</a>)</p>
                        <p>Principle investigator is <a href="https://de.wikipedia.org/wiki/Jessica_Burgner-Kahrs">Prof.
                            Dr.-Ing. Jessica Burgner-Kahrs</a></p>
                        <p>Relevant papers:
                            <br>
                            - <a href="https://arxiv.org/abs/2304.11850">
                                <i>Open Continuum Robotics â€“ One Actuation Module to Create them All
                                </i>
                            </a>
                            <br>
                            - <a href="https://openreview.net/forum?id=bYLFxFQPFtX">
                            <i>CTCR Prototype Development: An Obstacle in the Research Community?</i>
                            </a>
                        </p>
                    </td>
                </tr>

                <!-- Learning the Kinematics of CTCR -->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <img alt="clean-usnob" height="109" src="images/Project_CTCR_tinywow.jpg" width="160">
                    </td>
                    <td valign="middle" width="100%">
                        <p><i>"Learning the Kinematics of Tubular Continuum Robots"</i> (<a href="https://crl.utm.utoronto.ca/_pages/learning.html">link to project description</a>)</p>
                        <p>Principle investigator is <a href="https://de.wikipedia.org/wiki/Jessica_Burgner-Kahrs">Prof.
                            Dr.-Ing. Jessica Burgner-Kahrs</a></p>
                        <p>Relevant papers:
                            <br>
                            - <a href="https://doi.org/10.1109/IROS47612.2022.9981719">
                                <i>A Dataset and Benchmark for Learning the Kinematics of Concentric Tube Continuum
                                    Robots
                                </i>
                            </a>
                            <br>
                            - <a href="https://doi.org/10.1109/ICRA48506.2021.9562085">
                                <i>Learning-based Inverse Kinematics from Shape as Input for Concentric Tube
                                    Continuum Robots
                                </i>
                            </a>
                            <br>
                            - <a href="https://doi.org/10.15607/RSS.2019.XV.017">
                                <i>On the Merits of Joint Space and Orientation Representations in Learning the
                                    Forward Kinematics in SE(3)
                                </i>
                            </a>
                            <br>
                            - <a href="https://doi.org/10.1109/IROS.2018.8594451">
                                <i>Learning the Forward and Inverse Kinematics of a 6-DOF Concentric Tube Continuum
                                    Robot in SE(3)
                                </i>
                            </a>
                        </p>
                    </td>
                </tr>

                <!-- Algorithms for Continuum Robots -->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;background-color:#f4f5f4">
                        <img alt="clean-usnob" height="49" src="images/Project_algorithm_tinywow.png" width="160">
                    </td>
                    <td style="background-color:#f4f5f4" valign="middle" width="100%">
                        <p><i>"Algorithms for Continuum Robots"</i> (<a href="https://crl.utm.utoronto.ca/_pages/algorithms.html">link to project description</a>)</p>
                        <p>Principle investigator is <a href="https://de.wikipedia.org/wiki/Jessica_Burgner-Kahrs">Prof.
                            Dr.-Ing. Jessica Burgner-Kahrs</a></p>
                        <p>Relevant papers:
                            <br>
                            - <a href="https://doi.org/10.48550/arXiv.2412.16422">
                                <i>Using Clarke Transform to Create a Framework on the Manifold: From Sampling via Trajectory Generation to Control</i>
                            </a>
                            <br>
                            - <a href="https://doi.org/10.48550/arXiv.2412.16401">
                                <i>Clarke Transform and Encoder-Decoder Architecture for Arbitrary Joints Locations in Displacement-Actuated Continuum Robots</i>
                            </a>
                            <br>
                            - <a href="https://doi.org/10.48550/arXiv.2409.16501">
                                <i>Clarke Transform â€” A Fundamental Tool for Continuum Robotics</i>
                            </a>
                            <br>
                            - <a href="https://doi.org/10.1109/ICRA57147.2024.10610322">
                                <i>On the Disentanglement of Tube Inequalities in Concentric Tube Continuum Robots</i>
                            </a>
                            <br>
                            - <a href="https://doi.org/10.1109/IROS.2018.8594339">
                                <i>Quaternion-Based Smooth Trajectory Generator for Via Poses in SE(3) Considering Kinematic Limits in Cartesian Space</i>
                            </a>
                        </p>
                    </td>
                </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <!-- ACKNOWLEDGMENT -->
                <tbody>

                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Acknowledgment</heading>
                        <p>
                            I made it in the acknowledgment section of the following papers and video :)
                        </p>
                        - <a href="https://youtu.be/eP06ltS-pUs">
                            <i>
                                Continuum Robotics: Innovation inspired by Nature
                            </i>
                        </a>
                        (<a href="https://www.tunyaluxlangsub.ca/">Tunyalux Langsub's</a> Master's Research Project, 2024)
                        <br>
                        - <a href="https://doi.org/10.48550/arXiv.2409.09970">
                            <i>
                                A Non-Linear Model Predictive Task-Space Controller Satisfying Shape Constraints for Tendon-Driven Continuum Robots
                            </i>
                        </a>
                        (arXiv, 2024)
                        <br>
                        - <a href="https://doi.org/10.1109/RoboSoft60065.2024.10522016">
                            <i>A Lightweight Modular Segment Design for Tendon-Driven Continuum Robots with Pre-Programmable Stiffness
                            </i>
                        </a>
                        (IEEE RoboSoft 2024)
                        <br>
                        - <a href="https://doi.org/10.1109/LRA.2022.3185377">
                            <i>Shape Representation and Modeling of Tendon-Driven Continuum Robots Using Euler Arc Splines
                            </i>
                        </a>
                        (IEEE RA-L, 2022)
                        <br>
                        - <a href="https://doi.org/10.48550/arXiv.2011.12460">
                            <i>Experiments in Autonomous Driving Through Imitation Learning
                            </i>
                        </a>
                        (arXiv, 2020)
                    </td>
                </tr>

                </tbody>
            </table>

        </td>
    </tr>

    <!-- FOOTER -->
    <tfoot>
    <tr>
        <td style="padding:0px">
            <p style="text-align:left;font-size:small;color:#808080;">
                The page was designed to last. See the <a
                    href="https://jeffhuang.com/designed_to_last/">Manifesto for Preserving Content on
                the Web</a> by Jeff Huang for more information.
                <br>
                Design and source code from <a href="https://jonbarron.info/">Jon Barron</a>'s website.
            </p>
        </td>
    </tr>
    </tfoot>
</table>
</body>

</html>
